# https://opentelemetry.io/docs/collector/configuration/

# How data gets into the Collector
receivers:
  # Data sources: traces, metrics, logs
  otlp:
    protocols:
      grpc:
        endpoint: "otel-collector:4317"

processors:
  # Data sources: traces, metrics, logs
  memory_limiter:
    check_interval: 1s
    limit_percentage: 30
    spike_limit_percentage: 6
  # Data sources: traces, metrics, logs
  batch:
    timeout: 2s
    send_batch_max_size: 32768

# How you send data to one or more backends. Configuring an exporter does not enable it.
exporters:
  # Data sources: traces
  otlp/tempo:
    endpoint: tempo:4317
    tls:
      insecure: true
  otlp/jaeger:
    endpoint: jaeger:4317
    tls:
      insecure: true
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 300s
    sending_queue:
      enabled: true
      num_consumers: 10
      queue_size: 10000
  # this should work out to about 8M batches/second for 10s buffer
  # Data sources: metrics
  prometheus:
    endpoint: otel-collector:2113
  debug:
    verbosity: detailed
  # Log exporters
  otlphttp/logs:
    endpoint: "http://loki:3100/otlp"
    tls:
      insecure: true
service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [otlp/jaeger, otlp/tempo]
    metrics:
      receivers: [otlp]
      processors: [batch]
      exporters: [prometheus]
    logs:
      receivers: [otlp]
      processors: [batch]
      exporters: [otlphttp/logs]